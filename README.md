# Auto-BeatSaber: Generating New Content for VR Music Games
This is the repository for the Auto-BeatSaber project run by Amélie Anglade and Ryan Groves at the WiMIR 2019 workshop.

## Description of the project
In this project we dive into a specific problem at the intersection of music, gaming, and dance: the generation of a Beat Saber song level. Beat Saber is one of the most popular VR titles, in which the core of the gameplay is to rhythmically slice incoming boxes with light sabers to the sound of the beat. The game has sparked a huge community of modders who create their own choreographies to existing songs, as well as MIR-based tools (such as a MIDI converter or a BPM estimator) designed specifically to support level creation. The main task of this project is: how could we use machine learning to generate these choreographies automatically? Participants will also have the opportunity to learn from our experience as Data Science & MIR consultants as we will share our own structured process for problem-solving in the music tech industry.

## About us
Dr. Amélie Anglade is a Music Information Retrieval and Data Science consultant. She completed her PhD at Queen Mary University of London, before moving to industry, initially taking on positions in R&D labs such as Sony CSL, Philips Research and CNRS, and then being employed as an MIR expert for Music Tech startups such as SoundCloud and frestyl. For the past 5 years she has further developed her expertise in music identification and discovery–assisting startups and larger companies in the AI and music or multimedia space as an independent consultant, researching, prototyping, and scaling up Machine Learning solutions for them. Additionally, Amélie is a contributor to the EU Commision as an independent technical expert in charge of reviewing proposals and ongoing EU projects. In her spare time she attends music hackathons (15+ so far), and is a teacher and mentor for women in the field of data science through multiple organizations.

Ryan Groves is an award-winning music researcher and veteran developer of intelligent music systems. He received his Master’s in Music Technology from McGill University. In 2016, his work on computational music theory was awarded the Best Paper at ISMIR. He also has extensive experience in industry, building musical products that leverage machine learning. As the former Director of R&D for Zya, he developed a musical messenger app that automatically sings your texts, called Ditty. Ditty won the Best Music App of 2015 by the Appy Awards. More recently, he co-founded Melodrive, where he and his team built the first artificially intelligent composer that could compose music in realtime and react to interactive scenarios such as games and VR experiences. He now works as a consultant and startup advisor in Berlin, with a focus on expanding the use cases of music and audio through the application of AI.

## Resources

[Beat Saber demo video](https://www.youtube.com/watch?v=gV1sw4lfwFw)

[Beat Saber Mapping Community](https://bsmg.wiki/mapping)

[Beat Saber Mapping Tutorial](https://bsaber.com/benny-custom-mapping/)

[Beat Saber Map Data](https://drive.google.com/file/d/1E38y96FdLfA3rdPZl5qRK_Ho_EzyXiGz/view)

[Beat Saber Map Data format](https://docs.google.com/presentation/d/1dG-MlY4GkqcRKzf6fPkDtyFyce1BQVnDREXqnCZ3Us0/edit#slide=id.g55b4b4143f_22_0)

[Lakh MIDI Dataset](https://colinraffel.com/projects/lmd/)

[Amélie and Ryan's structured process to Music AI problem solving in industry (presentation recorded at Wallifornia MusicTech 2019)](https://youtu.be/nkJXLGi4mJ0)
